{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "from imutils import contours\n",
    "import scipy\n",
    "from scipy.spatial import distance as dist\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from os import path, listdir\n",
    "import os, random\n",
    "import time\n",
    "import seaborn  as sns\n",
    "import gc\n",
    "import sys\n",
    "import datetime\n",
    "import csv\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.patches as mpatches\n",
    "from collections import defaultdict\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need files which include russian letters in their names, read images with \n",
    "\n",
    "cv2.imdecode(np.fromfile('изображение.png', dtype=np.uint8), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "Look https://www.cyberforum.ru/python/thread2513567.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing(*arg):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotate img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for picture rotation (clockwise). Arguments:\n",
    "\n",
    "\\- img: picture after cv.imread.\n",
    "\n",
    "\\- rotate: int or str, 90,180 or 270. Default None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_pic(img,rotate = None):\n",
    "    rotate_dict = {90:cv.ROTATE_90_CLOCKWISE,\n",
    "              180:cv.ROTATE_180,\n",
    "              270:cv.ROTATE_90_COUNTERCLOCKWISE}\n",
    "    if rotate!=None:\n",
    "        img = cv.rotate(img, rotate_dict[int(rotate)])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for histogram plot.\n",
    "Arguments:\n",
    "\n",
    "\\- l_or_r: str, leaves or roots(or plants), is used for plot title\n",
    "\n",
    "\\- color_deff: dict, int or seaborn color palette, is used for coloring plot. If the type is int, meaning the quantity of groups on histogram, then seaborn Set2 will be used\n",
    "\n",
    "\\- df: pandas DataFrame, data for histogram plot\n",
    "\n",
    "\\- columns: dict or list, enumeration of needed columns in dataset. If it is necessary to merge different columns of df, you can use dict, where keys are test groups and values are columns names of df of test groups subsections. Isf you need the same task you also can use 2D list, but int numbers will be as group numbers. For example: columns = {'Monday': \\['M_col1', 'M_col2'\\], 'Friday':\\['F_col1', 'F_col2','F_col3'\\]}\n",
    "\n",
    "\\- is_save: bool, True or False, means the necessity of saving the plot\n",
    "\n",
    "\\- figname: str, ends with the needed format (jpg, png). Means the name of the file, if you want it to be saved. It also may contain the path to the needed folder.\n",
    "\n",
    "\\- top_border: int or float. Means the top border of the data. If the data has unreal outliers you can drop it using this threshold. The default value is 300\n",
    "\n",
    "\\- xlabel: str. The default is 'length, mm'\n",
    "\n",
    "\\- param: str. Means the measured parameter (for ex. length, square, width).The default is 'length'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def pic_filename(plot_type, plant_param, path):\n",
    "    report_filename = (str(path[:-1])+'_'+str(plant_param)+'_'+plot_type+\n",
    "                             '_'+str(datetime.datetime.now().date())+'.jpg')\n",
    "    return report_filename\n",
    "\n",
    "def hist(tmp_l,tmp_r_max, tmp_r_sum,tmp_p, whiskers_dict, is_save = False, figname=None):\n",
    "    fig, axes = plt.subplots(len(tmp_l.columns), 4, figsize=(35, 8*len(tmp_l.columns)))\n",
    "\n",
    "    matplotlib.rcParams.update({'font.size': 20})\n",
    "    param_type = 0\n",
    "    fig.suptitle('X axis: Length, mm (root max, root sum and leaves); Area, mm2 (plant area);'\n",
    "                 +'\\n Y axis: Frequency, rel. units')\n",
    "    param = ['leaves','roots_max','roots_sum', 'plant_area']\n",
    "    for tmp in [tmp_l,tmp_r_max, tmp_r_sum, tmp_p]:\n",
    "        iterator = 0\n",
    "        \n",
    "        for g in tmp_l.columns:\n",
    "            tmp[g] = tmp[tmp[g]>0][g]\n",
    "            plt.subplot(len(tmp.columns), 4, param_type+4*iterator+1)\n",
    "            mean = round(pd.Series(tmp[g].values.reshape(-1)).dropna().mean())\n",
    "            ci = round(whiskers_dict[param[param_type]][g])\n",
    "            label = (str(param[param_type])+' '+str(g) +'\\n'+\n",
    "                     f'shapiro p-value = {scipy.stats.shapiro(pd.Series(tmp[g].values.reshape(-1)).dropna())[1]:.2e}'+\n",
    "                    '\\n'+'mean = '+str(mean)+'$\\pm$'+str(ci))\n",
    "\n",
    "            sns.distplot(pd.Series(tmp[g].values.reshape(-1)).dropna(),\n",
    "                     color=sns.color_palette(\"Set2\")[iterator],\n",
    "                                 label=label)\n",
    "            plt.xlim(left = 0)\n",
    "            light = mpatches.Patch(color=sns.color_palette(\"Set2\")[param_type], label=r'{param}'.format(param =  param[param_type]))\n",
    "            plt.legend(loc = 'upper right')\n",
    "\n",
    "            iterator +=1\n",
    "        param_type+=1\n",
    "#     plt.show()\n",
    "    for ax in axes.flat:\n",
    "        ax.set(xlabel='x-label', ylabel='y-label')\n",
    "        \n",
    "    if is_save:\n",
    "        if figname is None:\n",
    "            figname = pic_filename('hist','l_rm_rs',path_to_file_folder_fixed)\n",
    "            print(figname)\n",
    "        plt.savefig(figname,bbox_inches = 'tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapiro-Wilk test function\n",
    "The function is used for checking the normality for the data. Perform the Shapiro-Wilk test for normality.\n",
    "\n",
    "The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution.\n",
    "\n",
    "The function builds the table with the test results for two type or data: for leaves and for roots. As a result the function returns 1D Pandas table with the results of the test.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "\\- df: pandas DataFrame. The data for the test\n",
    "\n",
    "\\- columns_l: dict, enumeration of needed columns in dataset with the data for leaves. If it is necessary to merge different columns of df, you can use dict, where keys are test groups and values are columns names of df of test groups subsections. Isf you need the same task you also can use 2D list, but int numbers will be as group numbers. For example: columns = {'Monday': \\['M_col1_leaves', 'M_col2_leaves'\\], 'Friday':\\['F_col1_leaves', 'F_col2_leaves','F_col3_leaves'\\]} \n",
    "\n",
    "\\- columns_r: dict, enumeration of needed columns in dataset with the data for roots. If it is necessary to merge different columns of df, you can use dict, where keys are test groups and values are columns names of df of test groups subsections. Isf you need the same task you also can use 2D list, but int numbers will be as group numbers. For example: columns = {'Monday': \\['M_col1_roots', 'M_col2_roots'\\], 'Friday':\\['F_col1_roots', 'F_col2_roots','F_col3_roots'\\]} \n",
    "\n",
    "\\-is_save: bool, True or False, means the necessity of saving the table\n",
    "\n",
    "\\- figname: str, ends with the needed format (csv). Means the name of the file, if you want it to be saved. It also may contain the path to the needed folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def shapiro_test (df, columns_dict):\n",
    "    import scipy.stats as sps\n",
    "    shapiro_table = pd.DataFrame(index =list(str(x) for x in list(columns_dict[list(columns_dict.keys())[0]].keys())),\n",
    "                                columns = columns_dict.keys())\n",
    "\n",
    "    for i in list(columns_dict.keys()): # columns\n",
    "        for j in shapiro_table.index: #strings\n",
    "            sh_result = scipy.stats.shapiro(df[columns_dict[i][str(j)]].dropna().values.reshape(-1))[1]\n",
    "            shapiro_table.loc[j][i]  =sh_result\n",
    "\n",
    "    return shapiro_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P-value function\n",
    "The function is used for checking the independence of two groups using T-test building the table for two type of the data: for leaves and for roots. As a result the function returns symetric 2D Pandas table with the results of the test containing 2 blocks (leaves and roots). Each cell is the result of the T-test by comparing groups of the column and of the row.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "\\- df: pandas DataFrame. The data for the test\n",
    "\n",
    "\\- columns_l: dict, enumeration of needed columns in dataset with the data for leaves. If it is necessary to merge different columns of df, you can use dict, where keys are test groups and values are columns names of df of test groups subsections. Isf you need the same task you also can use 2D list, but int numbers will be as group numbers. For example: columns = {'Monday': \\['M_col1_leaves', 'M_col2_leaves'\\], 'Friday':\\['F_col1_leaves', 'F_col2_leaves','F_col3_leaves'\\]} \n",
    "\n",
    "\\- columns_r: dict, enumeration of needed columns in dataset with the data for roots. If it is necessary to merge different columns of df, you can use dict, where keys are test groups and values are columns names of df of test groups subsections. Isf you need the same task you also can use 2D list, but int numbers will be as group numbers. For example: columns = {'Monday': \\['M_col1_roots', 'M_col2_roots'\\], 'Friday':\\['F_col1_roots', 'F_col2_roots','F_col3_roots'\\]} \n",
    "\n",
    "\\-is_save: bool, True or False, means the necessity of saving the table\n",
    "\n",
    "\\- figname: str, ends with the needed format (csv). Means the name of the file, if you want it to be saved. It also may contain the path to the needed folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pvalue_calc(df1,df2,is_norm):\n",
    "    ret = 0\n",
    "    is_not_norm = not is_norm\n",
    "    method = is_norm*'Unpaired T-test'+is_not_norm*'Mann Whitney U-test'\n",
    "    if method=='Unpaired T-test':\n",
    "        ret = scipy.stats.ttest_ind(df1,df2)\n",
    "    if method=='Mann Whitney U-test':\n",
    "        ret = scipy.stats.mannwhitneyu(df1,df2, use_continuity = False ,alternative = 'two-sided')\n",
    "    return ret        \n",
    "\n",
    "def p_value_function (df, columns, is_norm):\n",
    "    import scipy.stats as sps\n",
    "    pvalue_table = pd.DataFrame(index = list(str(x) for x in columns.keys()),\n",
    "                                columns=list(str(x) for x in columns.keys()))\n",
    "    for i in (list(columns.keys())):\n",
    "        for j in (list(columns.keys())):\n",
    "            pvalue_table[str(i)].loc[str(j)] = pvalue_calc(pd.Series(df[columns[i]].values.reshape(-1)).dropna(),\n",
    "                                                            pd.Series(df[columns[j]].values.reshape(-1)).dropna(),is_norm)[1]\n",
    "    pvalue_table.fillna(value='.', inplace = True)\n",
    "\n",
    "    return pvalue_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Информация о пакете Annotator взята из ресурса:\n",
    "\n",
    "https://levelup.gitconnected.com/statistics-on-seaborn-plots-with-statannotations-2bfce0394c00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar-plot function\n",
    "Arguments:\n",
    "\n",
    "\\- l_or_r: str, leaves or roots(or plants), is used for plot title\n",
    "\n",
    "\\- color_deff: dict, int or seaborn color palette, is used for coloring plot. If the type is int, meaning the quantity of groups on histogram, then seaborn Set2 will be used\n",
    "\n",
    "\\- df: pandas DataFrame, data for histogram plot\n",
    "\n",
    "\\- columns: dict or 1d list, enumeration of needed columns in dataset. If it is necessary to merge different columns of df, you can use dict, where keys are test groups and values are columns names of df of test groups subsections. Isf you need the same task you also can use 2D list, but int numbers will be as group numbers. For example: columns = {'Monday': \\['M_col1', 'M_col2'\\], 'Friday':\\['F_col1', 'F_col2','F_col3'\\]}. // If you don't need to merge df, you can just use 1d list with group names, for example \\['Monday', 'Friday'\\]\n",
    "\n",
    "\\- pv_table: pandas DataFrame. P-value data to print them on the plot.\n",
    "\n",
    "\\- control_label: int or str. Name of the control group. This value also should be in columns.keys() (or in 1d list of columns). The type is dependent on the columns.keys()s elements type\n",
    "\n",
    "\\- comparison_points: list of str or int. Names of groups for comparison with the control group. The elements of the list must be in columns.keys() (or in 1d list of columns), and types also should coincide. This parametr is optional, the default is all the groups exept control_label. If you don't need all the groups to be compared, define this parametr. \n",
    "\n",
    "\\- is_save: bool, True or False, means the necessity of saving the plot.The default is False.\n",
    "\n",
    "\\- figname: str, ends with the needed format (jpg, png). Means the name of the file, if you want it to be saved. It also may contain the path to the needed folder.\n",
    "\n",
    "\\- union_DF_length: int. Means the length of tmp DataFrame. This tmp DataFrame is needed to merge different collumns of the same group (If you have several photos as a part of the same group, you will have several columns in resulted df). The default value is 130\n",
    "\n",
    "\\- xlabel: str. The default is 'group number'\n",
    "\n",
    "\\- ylabel: str. The default is 'length, mm'\n",
    "\n",
    "\\- param: str. Means the measured parameter (for ex. length, square, width).The default is 'length'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pic_filename(plot_type, plant_param, path):\n",
    "    report_filename = (str(path[:-1])+'_'+str(plant_param)+'_'+plot_type+\n",
    "                             '_'+str(datetime.datetime.now().date())+'.jpg')\n",
    "    return report_filename\n",
    "\n",
    "def bar_plot_function(l_or_r, color_deff, df, columns, pv_table,\n",
    "                      is_save = False, figname=None,  union_DF_length = 500, xlabel = 'group label', ylabel = 'length, mm',\n",
    "                      param = 'length', auto_or_man = 'automatic',  is_drop_outliers = False):\n",
    "    \n",
    "    if type(columns)==dict:\n",
    "        tmp = pd.DataFrame(columns=list(columns.keys()),index=np.arange(union_DF_length))\n",
    "        for i in columns.keys():\n",
    "            tmp[i] = pd.DataFrame(pd.Series(df[columns[i]].values.reshape(-1)).dropna()) \n",
    "        group_number_names = list(columns.keys())\n",
    "    elif type(columns)==list: #### still 1D\n",
    "        tmp = df\n",
    "        group_number_names = columns ## если 2D массив, то range где кажд индекс +1 range(1, len(columns)+1)\n",
    "    if is_drop_outliers:\n",
    "        tmp = drop_outliers(tmp, tmp.columns)         \n",
    "    c = sns.color_palette(\"Set2\")\n",
    "        \n",
    "\n",
    "    matplotlib.rcParams.update({'font.size': 20})\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    fig.suptitle(r'{0}'.format(l_or_r))\n",
    "    \n",
    "          \n",
    "    a = sns.barplot(ax = axes[0], data=tmp[group_number_names], palette=c)\n",
    "    plt.xlabel(xlabel, fontsize = 20)\n",
    "    plt.ylabel(ylabel, fontsize = 20)\n",
    "    \n",
    "    for ax in axes.flat:\n",
    "        ax.set( ylabel=ylabel)\n",
    "    \n",
    "    whiskers = defaultdict(type(group_number_names[0]))\n",
    "    i=0\n",
    "    for j in group_number_names:\n",
    "        whiskers[j] = ((a.get_lines()[i].get_data()[1][1]-a.get_lines()[i].get_data()[1][0])/2)\n",
    "        i+=1\n",
    "    \n",
    "    matplotlib.rcParams.update({'font.size': 20}) \n",
    "\n",
    "    for i in range(0,pv_table.shape[1]):\n",
    "        for j in range(0,pv_table.shape[1]):\n",
    "            if i>j:\n",
    "                pv_table[pv_table.columns[i]].loc[pv_table.columns[j]] = np.nan\n",
    "            if pv_table[pv_table.columns[i]].loc[pv_table.columns[j]]>0.05:\n",
    "                pv_table[pv_table.columns[i]].loc[pv_table.columns[j]] = 1\n",
    "            if pv_table[pv_table.columns[i]].loc[pv_table.columns[j]]<0.05:\n",
    "                pv_table[pv_table.columns[i]].loc[pv_table.columns[j]] = 0.00003\n",
    "                \n",
    "    f=np.array(pv_table, dtype='float64')\n",
    "    a = [[0.247, 0.41176, 0.349],[0.624, 0.8967, 0.81] ]\n",
    "    sns.heatmap(f, xticklabels=pv_table.columns, yticklabels=pv_table.columns, cbar=False, cmap = a, ax = axes[1])\n",
    "    dark = mpatches.Patch(color=a[0], label='p_value<0.05')\n",
    "    light = mpatches.Patch(color=a[1], label='p_value>0.05')\n",
    "    plt.legend(handles=[dark, light])\n",
    "\n",
    "    if is_save:\n",
    "        if figname is None:\n",
    "            figname = pic_filename('bar',l_or_r.replace(' ', ''),path_to_file_folder_fixed)\n",
    "            print(figname)\n",
    "        plt.savefig(figname,bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return tmp, whiskers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed germination counter\n",
    "\n",
    "Function for counting the rate of non germinated seeds in all groups. The default value to consider the seed as nongerminated is 10 mm. If any root of leave has appropriate length, the seed is considered germinated (look at the table).\n",
    "\n",
    "\n",
    "| l  r || l  r || l  r || l  r || l  r |\n",
    "|   --- || --- ||  --- ||   --- ||   --- |\n",
    "| 16   0 || 9  9 || 9  50 || 16  50 ||  0 5 |\n",
    "|   V || X ||  V ||   V ||   X |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_germination(df,group_names,threshold = 10, is_save = False, figname = None):\n",
    "    non_germinated_table = pd.DataFrame(columns=group_names, index=np.arange(1))\n",
    "    for i in group_names:\n",
    "        l_columns = 'leaves_length_'+path_to_file_folder_fixed+i\n",
    "        r_columns = 'roots_max_length_'+path_to_file_folder_fixed+i\n",
    "        l = df[[i for i in measure_full2.columns if i.startswith(l_columns)]]\n",
    "        r = df[[i for i in measure_full2.columns if i.startswith(r_columns)]]\n",
    "        full_number = (np.array((r>=0))*np.array((l>=0))).sum()\n",
    "        non_germinated_table[i].loc[0] = 1-(np.array((r<threshold))*np.array((l<threshold))).sum()/full_number\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)    \n",
    "    plt.xlabel('group label', fontsize = 20)\n",
    "    plt.ylabel('distribution density', fontsize = 20)    \n",
    "    sns.barplot(x=non_germinated_table.columns, y = non_germinated_table.values[0],\n",
    "                palette=sns.color_palette(\"Set2\"))\n",
    "    plt.title('Germination efficiency', fontsize=20)\n",
    "\n",
    "    if is_save:\n",
    "        if figname is None:\n",
    "            figname = pic_filename('bar','seed_germ',path_to_file_folder_fixed)\n",
    "        plt.savefig(figname)\n",
    "    plt.show()\n",
    "    return non_germinated_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length calculating\n",
    "\n",
    "The function calculates the plant part length by its width, square and pixel_per_metric coefficient. If the width is zero, functon returns length value as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length(width, square, pixel):\n",
    "    if (width!=0):\n",
    "        length = square/(width*pixel)\n",
    "    else:\n",
    "        length = 0\n",
    "    return length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folders_list_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если папок для перечисления много, то можно вызвать функцию, которая скомпанует всё что лежит в папке в один лист"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folders_list_function(path_to_file_folder):\n",
    "    folders_list=[]\n",
    "    for filename_in_folder in listdir(path_to_file_folder):\n",
    "        folders_list.append(filename_in_folder)\n",
    "\n",
    "    if '.ipynb_checkpoints' in folders_list:\n",
    "        folders_list.remove('.ipynb_checkpoints')\n",
    "    if 'template' in folders_list:\n",
    "        folders_list.remove('template')\n",
    "    return folders_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### files_dicts\n",
    "\n",
    "The function builds dicts with names of the columns in df, based on photos filenames. The main feachure is that all the columns names are merged by test groups names. Keys are the test groups names. Returns leaves_dict, roots_dict, roots_area_dict, plant_area_dict -- dicts with columns related to a specific test group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_dicts(path_to_file_folder_fixed):\n",
    "    plant_parameters = ['roots_sum','roots_max','plant_area','leaves']\n",
    "    \n",
    "    folders_list = folders_list_function(path_to_file_folder_fixed)\n",
    "\n",
    "    leaves_dict = dict()\n",
    "    for i in folders_list:\n",
    "        leaves_dict[i] = []\n",
    "\n",
    "    for g in folders_list:\n",
    "    #     pic_num=0\n",
    "        path_to_file_folder = path_to_file_folder_fixed\n",
    "        path_to_file_folder = path.join(path_to_file_folder, str(g)+'/')\n",
    "        for filename_in_folder in listdir(path_to_file_folder):\n",
    "    #         pic_num +=1\n",
    "    #         if pic_num>3:\n",
    "    #             continue\n",
    "            if filename_in_folder!='.ipynb_checkpoints':\n",
    "                file_name = path.join(path_to_file_folder, filename_in_folder)\n",
    "                leaves_dict[g].append('leaves_length_'+file_name)\n",
    "\n",
    "    roots_dict = dict()\n",
    "    for i in folders_list:\n",
    "        roots_dict[i] = []   \n",
    "\n",
    "    for g in folders_list:\n",
    "    #     pic_num=0\n",
    "        path_to_file_folder = path_to_file_folder_fixed\n",
    "        path_to_file_folder = path.join(path_to_file_folder, str(g)+'/')\n",
    "        for filename_in_folder in listdir(path_to_file_folder):\n",
    "    #         pic_num +=1\n",
    "    #         if pic_num>3:\n",
    "    #             continue\n",
    "            if filename_in_folder!='.ipynb_checkpoints':\n",
    "                file_name = path.join(path_to_file_folder, filename_in_folder)\n",
    "                roots_dict[g].append('roots_length_'+file_name)\n",
    "\n",
    "    roots_max_dict = dict()\n",
    "    for i in folders_list:\n",
    "        roots_max_dict[i] = [] \n",
    "\n",
    "    for g in folders_list:\n",
    "        path_to_file_folder = path_to_file_folder_fixed\n",
    "        path_to_file_folder = path.join(path_to_file_folder, str(g)+'/')\n",
    "        for filename_in_folder in listdir(path_to_file_folder):\n",
    "            if filename_in_folder!='.ipynb_checkpoints':\n",
    "                file_name = path.join(path_to_file_folder, filename_in_folder)\n",
    "                roots_max_dict[g].append('roots_max_length_'+file_name)\n",
    "\n",
    "    plant_area_dict = dict()\n",
    "    for i in folders_list:\n",
    "        plant_area_dict[i] = [] \n",
    "\n",
    "    for g in folders_list:\n",
    "        path_to_file_folder = path_to_file_folder_fixed\n",
    "        path_to_file_folder = path.join(path_to_file_folder, str(g)+'/')\n",
    "        for filename_in_folder in listdir(path_to_file_folder):\n",
    "            if filename_in_folder!='.ipynb_checkpoints':\n",
    "                file_name = path.join(path_to_file_folder, filename_in_folder)\n",
    "                plant_area_dict[g].append('plant_area_'+file_name)\n",
    "                \n",
    "    dicts = {'roots_sum':roots_dict,\n",
    "             'roots_max':roots_max_dict,\n",
    "             'plant_area': plant_area_dict,\n",
    "             'leaves':leaves_dict}\n",
    "    \n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop outliers\n",
    "\n",
    "Function drops values lying lower or upper than 25 or 75 quartille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_outliers(df, columns):\n",
    "    for x in list(columns):\n",
    "#         print(x)\n",
    "#         print(df[x].values.reshape(-1))\n",
    "        q75,q25 = np.percentile(pd.Series(df[x].values.reshape(-1)).dropna(),[75,25])\n",
    "#         print(q75,q25)\n",
    "        intr_qr = q75-q25\n",
    "\n",
    "        max = q75+(1.5*intr_qr)\n",
    "        min = q25-(1.5*intr_qr)\n",
    "        \n",
    "        df.loc[df[x] < min,x] = np.nan\n",
    "        df.loc[df[x] > max,x] = np.nan\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно попробовать посчитать сколько ненулевых пикселей в маске и это будет быстрее чем попиксельный подсчет. Т к тип маски это массив нулевых-ненулевых пиксилей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_color_conditions(pixel ,h1=0, h2=255, s1=0, s2=255, v1=0, v2=255):\n",
    "    h, s, v = pixel # pixel = img_hsv[x, y]\n",
    "    h_condition = (h>=h1)&(h<=h2)\n",
    "    s_condition = (s>=s1)&(s<=s2)\n",
    "    v_condition = (v>=v1)&(v<=v2)\n",
    "    full_condition = h_condition*s_condition*v_condition\n",
    "    return full_condition\n",
    "\n",
    "def drop_seeds_slow(src, contours, h1=0, h2=255, s1=0, s2=255, v1=0, v2=255):\n",
    "    src_hsv  = cv.cvtColor(src, cv.COLOR_BGR2HSV)\n",
    "    seeds_square_list = np.zeros(len(contours))\n",
    "    h_min = np.array((h1, s1, v1), np.uint8)\n",
    "    h_max = np.array((h2, s2, v2), np.uint8)\n",
    "    tresh = cv.inRange(src_hsv, h_min, h_max)\n",
    "    for i in range(len(contours)):\n",
    "        c = contours[i]\n",
    "        cimg1 = np.zeros_like(src)\n",
    "        cv.drawContours(cimg1, contours, i, color=255, thickness=-1)\n",
    "        pts = np.where(cimg1 == 255)\n",
    "        for x, y in zip(pts[0], pts[1]):                   \n",
    "            if pixel_color_conditions(src_hsv[x, y], h1, h2, s1, s2, v1, v2):\n",
    "                src_hsv[x, y] = [0,0,0]\n",
    "                seeds_square_list[i]+=1\n",
    "    src  = cv.cvtColor(src_hsv, cv.COLOR_HSV2BGR)\n",
    "    plt.figure(figsize=(14,14))\n",
    "    plt.imshow(tresh)\n",
    "    plt.show()\n",
    "    return src, seeds_square_list\n",
    "\n",
    "def drop_seeds(src, h1=0, h2=255, s1=0, s2=255, v1=0, v2=255):\n",
    "    src_hsv  = cv.cvtColor(src, cv.COLOR_BGR2HSV)\n",
    "    h_min = np.array((h1, s1, v1), np.uint8)\n",
    "    h_max = np.array((h2, s2, v2), np.uint8)\n",
    "    tresh = cv.inRange(src_hsv, h_min, h_max)\n",
    "    tresh=cv.bitwise_not(tresh)\n",
    "    mask = cv.bitwise_or(src, src, mask=tresh)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear approximation\n",
    "After seed position search it is needed to find the line dividing leaves and roots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_approx(x,y):\n",
    "    x=np.array(x).reshape(len(x),1)# Построй м модель\n",
    "    m=LinearRegression()\n",
    "    z1=m.fit(x,y)\n",
    "    z1.score(x,y)# Показывать примерный эффект - 1.0\n",
    "    z1.predict([[10]])#//Прогноз, результат31\n",
    "    p=z1.coef_# Отображение коэффициента\n",
    "    q=z1.intercept_\n",
    "    return p, q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color range counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция считает, сколько пикселей на картинке лежит в данном цветовом диапазоне внутри каждого контура. На выходе дает массивразмером совпадающим с "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_range_counter(src, contours, h1=0, h2=255, s1=0, s2=255, v1=0, v2=255):\n",
    "    src_hsv  = cv.cvtColor(src, cv.COLOR_BGR2HSV)\n",
    "    h_min = np.array((h1, s1, v1), np.uint8)\n",
    "    h_max = np.array((h2, s2, v2), np.uint8)\n",
    "    thresh = cv.inRange(src_hsv, h_min, h_max)\n",
    "    thresh = np.clip(thresh, 0,1)\n",
    "    counter = np.zeros(len(contours))\n",
    "    for i in range(len(contours)):\n",
    "        c = contours[i]\n",
    "        cimg1 = np.zeros_like(thresh)\n",
    "        cv.drawContours(cimg1, contours, i, color=255, thickness=-1)\n",
    "#         plt.figure(figsize=(14,14))\n",
    "#         plt.imshow(cimg1)\n",
    "#         plt.show()\n",
    "#         plt.figure(figsize=(14,14))\n",
    "#         plt.imshow(thresh)\n",
    "#         plt.show()\n",
    "\n",
    "#         print('plant area = ', cv.contourArea(c) )\n",
    "        cimg1 = np.clip(cimg1, 0 ,1)\n",
    "        counter[i] = (cimg1*thresh).sum()\n",
    "#     print(counter)\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_paper (src, template_size, square_threshold, position_x_axes, canny_top = 100, canny_bottom = 10, morf = 7, gauss = 3):\n",
    "    gr = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
    "    bl=cv.GaussianBlur(src,(gauss,gauss),0)\n",
    "    canny = cv.Canny(bl, canny_bottom, canny_top)\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (int(morph), int(morph)))\n",
    "    closed = cv.morphologyEx(canny, cv.MORPH_CLOSE, kernel)\n",
    "    contours0 = cv.findContours(closed.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)[0]\n",
    "    # contours0 = contours0[0] if imutils.is_cv2() else contours0[1]\n",
    "    (contours0, _) = contours.sort_contours(contours0)\n",
    "    \n",
    "\n",
    "    \n",
    "    for cont in contours0:\n",
    "#         cv.drawContours(src,[cont],0,(0,255,0),-2)\n",
    "        center, radius = cv.minEnclosingCircle(cont)\n",
    "        if (cv.contourArea(cont)>square_threshold)&(center[0]>position_x_axes): #position = src.shape[1]//8\n",
    "            sm = cv.arcLength(cont, True)\n",
    "            apd = cv.approxPolyDP(cont, 0.025*sm, True)\n",
    "            center, radius = cv.minEnclosingCircle(cont)\n",
    "            cv.drawContours(src, [cont], -1, (0,255,0), -2)\n",
    "            if len(apd) == 4:\n",
    "                is_paper_founded = True\n",
    "                paper = cont\n",
    "    #                 print('paper')\n",
    "                cv.drawContours(src, [cont], -1, (0,255,0), -2)\n",
    "                pixelsPerMetric = 7.6\n",
    "                box = cv.minAreaRect(cont)\n",
    "                box = cv.boxPoints(box)\n",
    "                box = np.array(box, dtype=\"int\")\n",
    "                (tl, tr, br, bl) = box\n",
    "                (tltrX, tltrY) = midpoint(tl, tr)\n",
    "                (blbrX, blbrY) = midpoint(bl, br)\n",
    "                (tlblX, tlblY) = midpoint(tl, bl)\n",
    "                (trbrX, trbrY) = midpoint(tr, br)\n",
    "                dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))\n",
    "                dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))\n",
    "    #             if (dB/template_size > (square_threshold/)):                \n",
    "                pixelsPerMetric = math.sqrt(cv.contourArea(cont)/(template_size))\n",
    "                ppm.append(pixelsPerMetric)\n",
    "            else:\n",
    "                pixelsPerMetric = ppm[-1]\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "            rect = cv.minAreaRect(apd)\n",
    "            box = cv.boxPoints(rect) # поиск четырех вершин прямоугольника\n",
    "            box = np.int0(box) # округление координат\n",
    "            print(pixelsPerMetric)\n",
    "            cv.drawContours(src,[cont],0,(0,255,0),-2)\n",
    "            break\n",
    "    plt.figure(figsize=(14,14))\n",
    "    plt.imshow(src)\n",
    "    plt.show()\n",
    "    return pixelsPerMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_file(path_to_file_folder):\n",
    "    a=random.choice(os.listdir(path_to_file_folder))\n",
    "    while (a=='template')|(a=='.ipynb_checkpoints'):\n",
    "        a=random.choice(os.listdir(path_to_file_folder))\n",
    "    path_to_file = path.join(path_to_file_folder, a+'/')\n",
    "    b = random.choice(os.listdir(path_to_file))\n",
    "    while (b=='.ipynb_checkpoints'):\n",
    "        b=random.choice(os.listdir(path_to_file))\n",
    "    path_to_file = path.join(path_to_file, b)\n",
    "    return path_to_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class picture_params:   \n",
    "    count = 0  \n",
    "    def __init__(self):  \n",
    "        picture_params.count += 1 \n",
    "    def contour_params(self, morph, gauss, canny_bottom, canny_top): \n",
    "        self.morph = morph \n",
    "        self.gauss = gauss \n",
    "        self.canny_bottom = canny_bottom \n",
    "        self.canny_top = canny_top\n",
    "  \n",
    "    def color(self, h1,h2,s1,s2,v1,v2):\n",
    "        self.h1 = h1\n",
    "        self.h2 = h2\n",
    "        self.s1 = s1\n",
    "        self.s2 = s2\n",
    "        self.v1 = v1\n",
    "        self.v2 = v2\n",
    "    \n",
    "    def display_count(self):  \n",
    "        print('Groups total number: %d' % picture_params.count)\n",
    "        \n",
    "    def return_bl_params(self):  \n",
    "        return self.morph, self.gauss, self.canny_bottom, self.canny_top \n",
    "    def display_element(self):\n",
    "        attrs = vars(self)\n",
    "        print(', '.join(\"%s: %s\" % item for item in attrs.items()))\n",
    "        \n",
    "    def return_colors(self):\n",
    "        return self.h1,self.h2,self.s1,self.s2,self.v1,self.v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main.AUTOMATIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_x_axes(src,divider):\n",
    "    return src.shape[1]//divider\n",
    "\n",
    "ppm = [7.45]\n",
    "rotate = 270\n",
    "path_to_file_folder_fixed = '4567days/4567days/'\n",
    "paper_area = 79*79\n",
    "paper_area_thresold = 5000\n",
    "x_pos_divider = 10\n",
    "contour_area_threshold = 1000 # look at your img size and evaluate the threshold, 1000 is recomended\n",
    "template_filename = path_to_file_folder_fixed+'template/template.JPG'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bluring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    def nothing(*arg):\n",
    "        pass\n",
    "\n",
    "\n",
    "    \n",
    "cv.namedWindow( \"result\", cv.WINDOW_NORMAL ) # создаем главное окно\n",
    "cv.namedWindow( \"b\" ) # создаем окно настроек\n",
    "\n",
    "file_name =  random_file(path_to_file_folder_fixed)\n",
    "src = cv.imread(file_name)\n",
    "src = rotate_pic(src, rotate)\n",
    "# создаем 6 бегунков для настройки начального и конечного цвета фильтра\n",
    "cv.createTrackbar('morph', 'b', 0, 7, nothing)\n",
    "cv.createTrackbar('gauss', 'b', 0, 7, nothing)\n",
    "cv.createTrackbar('canny_bottom', 'b', 0, 255, nothing)\n",
    "cv.createTrackbar('canny_top', 'b', 255, 255, nothing)\n",
    "crange = [0,0,0, 0,0,0]\n",
    "\n",
    "hsv = cv.cvtColor(src, cv.COLOR_BGR2HSV )\n",
    "\n",
    "while True:\n",
    "#     img = cv.imread('6finish.jpg')\n",
    "    \n",
    "    # считываем значения бегунков\n",
    "    \n",
    "    init = [0,0,0,0]\n",
    "    morph = cv.getTrackbarPos('morph', 'b')\n",
    "    gauss = cv.getTrackbarPos('gauss', 'b')\n",
    "    canny_bottom = cv.getTrackbarPos('canny_bottom', 'b')\n",
    "    canny_top = cv.getTrackbarPos('canny_top', 'b')\n",
    "    \n",
    "    morph = 2* morph+1\n",
    "    gauss = 2*gauss+1\n",
    "    \n",
    "    l = [morph, gauss, canny_bottom, canny_top]\n",
    "    is_change = True\n",
    "    is_change = any(init[i]!=l[i] for i in range (4))\n",
    "    init = l\n",
    "     \n",
    " \n",
    "    ch = cv.waitKey(5)\n",
    "    if ch == 27:\n",
    "        break\n",
    "\n",
    "    if (is_change):\n",
    "        src=cv.imread(file_name)\n",
    "        src = rotate_pic(src, rotate)\n",
    "        gr = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
    "        #         bl = cv.medianBlur(src, 3)\n",
    "        bl=cv.GaussianBlur(src,(gauss,gauss),0)\n",
    "\n",
    "        #         ret, thresh = cv.threshold(bl, 120,255,0)\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (int(morph), int(morph)))\n",
    "        closed = cv.morphologyEx(bl, cv.MORPH_CLOSE, kernel)\n",
    "        canny = cv.Canny(closed, canny_bottom, canny_top)\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (int(morph), int(morph)))\n",
    "        closed = cv.morphologyEx(canny, cv.MORPH_CLOSE, kernel)\n",
    "        contours0 = cv.findContours(closed.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)[0]\n",
    "        # contours0 = contours0[0] if imutils.is_cv() else contours0[1]\n",
    "        (contours0, _) = contours.sort_contours(contours0)\n",
    "\n",
    "\n",
    "\n",
    "        for cont in contours0:\n",
    "            center, radius = cv.minEnclosingCircle(cont)\n",
    "            if ((cv.contourArea(cont)>contour_area_threshold)&\n",
    "                (center[0] >src.shape[1]//4)&(center[0] < 2*src.shape[1]//3)):\n",
    "\n",
    "                #сглаживание и определение количества углов\n",
    "                sm = cv.arcLength(cont, True)\n",
    "                apd = cv.approxPolyDP(cont, 0.02*sm, True)\n",
    "                cv.drawContours(src, [cont], -1, (255,0,0), -2)\n",
    "        \n",
    "    if ch == 49:\n",
    "        group_param = picture_params()\n",
    "        picture_params.contour_params(group_param, morph,gauss,canny_bottom,canny_top)\n",
    "    cv.imshow('result', src)\n",
    "    \"\"\n",
    "cv.destroyAllWindows()\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roots and leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    def nothing(*arg):\n",
    "        pass\n",
    "\n",
    "\n",
    "    \n",
    "cv.namedWindow( \"result\", cv.WINDOW_NORMAL ) # создаем главное окно\n",
    "cv.namedWindow( \"b\" ) # создаем окно настроек\n",
    "\n",
    "file_name = random_file(path_to_file_folder_fixed)\n",
    "src = cv.imread(file_name)\n",
    "src = rotate_pic(src, rotate)\n",
    "template = cv.imread(template_filename,0)\n",
    "template = rotate_pic(template, rotate)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "methods = ['cv.TM_CCOEFF_NORMED']\n",
    "for meth in methods:\n",
    "    img = cv.imread(file_name,0)\n",
    "    img = rotate_pic(img, rotate)\n",
    "    method = eval(meth)\n",
    "    # Apply template Matching\n",
    "    res = cv.matchTemplate(img,template,method)\n",
    "    threshold = 0.55\n",
    "    loc = np.where( res > threshold)\n",
    "    numbers0=[]\n",
    "    for pt in zip(*loc[::-1]):\n",
    "        if (pt[0] > src.shape[1]/3)&((pt[0] < 2*src.shape[1]/3)):\n",
    "            numbers0.append(pt[0])\n",
    "#             cv.rectangle(img, pt, (pt[0] + w, pt[1] + h), (0,0,255), 5)\n",
    "\n",
    "    numbers = pd.Series(numbers0)\n",
    "    Mean = numbers.mean()\n",
    "    Median = numbers.median()\n",
    "    Mode = numbers.mode()[0]   \n",
    "    mean_left_x = int(Mode)-w//4\n",
    "    mean_right_x = int(Mode) + 3*w//4\n",
    "    mean_left_x = round(mean_left_x)\n",
    "    mean_right_x = round(mean_right_x)\n",
    "\n",
    "overlay = src.copy()\n",
    "cv.rectangle(overlay, (0,src.shape[0]), (mean_left_x, 0), (0,224,79), -1)\n",
    "opacity = 0.25\n",
    "cv.rectangle(overlay, (mean_right_x, src.shape[0]), (src.shape[1],0), (240,0,255), -5)\n",
    "cv.addWeighted(overlay, opacity, src, 1 - opacity, 0, src)\n",
    "\n",
    "# создаем 6 бегунков для настройки начального и конечного цвета фильтра\n",
    "cv.createTrackbar('h1', 'b', 0, 255, nothing)\n",
    "cv.createTrackbar('s1', 'b', 0, 255, nothing)\n",
    "cv.createTrackbar('v1', 'b', 0, 255, nothing)\n",
    "cv.createTrackbar('h2', 'b', 255, 255, nothing)\n",
    "cv.createTrackbar('s2', 'b', 255, 255, nothing)\n",
    "cv.createTrackbar('v2', 'b', 255, 255, nothing)\n",
    "crange = [0,0,0, 0,0,0]\n",
    "\n",
    "hsv = cv.cvtColor(src, cv.COLOR_BGR2HSV )\n",
    "\n",
    "while True:\n",
    "#     img = cv.imread('6finish.jpg')\n",
    "\n",
    "    # считываем значения бегунков\n",
    "    h1 = cv.getTrackbarPos('h1', 'b')\n",
    "    s1 = cv.getTrackbarPos('s1', 'b')\n",
    "    v1 = cv.getTrackbarPos('v1', 'b')\n",
    "    h2 = cv.getTrackbarPos('h2', 'b')\n",
    "    s2 = cv.getTrackbarPos('s2', 'b')\n",
    "    v2 = cv.getTrackbarPos('v2', 'b')\n",
    "\n",
    "\n",
    "    # формируем начальный и конечный цвет фильтра\n",
    "    h_min = np.array((h1, s1, v1), np.uint8)\n",
    "    h_max = np.array((h2, s2, v2), np.uint8)\n",
    "\n",
    "    # накладываем фильтр на кадр в модели HSV\n",
    "    thresh = cv.inRange(hsv, h_min, h_max)\n",
    "\n",
    "    cv.imshow('result', thresh) \n",
    " \n",
    "    ch = cv.waitKey(5)\n",
    "    if ch == 27:\n",
    "        break\n",
    "    if ch == 49:\n",
    "        v_min_l = cv.getTrackbarPos('v1', 'b')\n",
    "        v_max_l = cv.getTrackbarPos('v2', 'b')\n",
    "        s_min_l = cv.getTrackbarPos('s1', 'b')\n",
    "        s_max_l = cv.getTrackbarPos('s2', 'b')\n",
    "        h_max_l = cv.getTrackbarPos('h2', 'b')\n",
    "        h_min_l = cv.getTrackbarPos('h1', 'b')\n",
    "        group_param_leaves = picture_params()\n",
    "        picture_params.color(group_param_leaves,h_min_l,h_max_l,s_min_l,s_max_l,v_min_l,v_max_l)\n",
    "    if ch == 50:\n",
    "        v_min_r = cv.getTrackbarPos('v1', 'b')\n",
    "        v_max_r = cv.getTrackbarPos('v2', 'b')\n",
    "        s_min_r = cv.getTrackbarPos('s1', 'b')\n",
    "        s_max_r = cv.getTrackbarPos('s2', 'b')\n",
    "        h_max_r = cv.getTrackbarPos('h2', 'b')\n",
    "        h_min_r = cv.getTrackbarPos('h1', 'b')\n",
    "        group_param_roots = picture_params()\n",
    "        picture_params.color(group_param_roots,h_min_r,h_max_r,s_min_r,s_max_r,v_min_r,v_max_r)\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "del src, img, hsv, thresh, overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    def nothing(*arg):\n",
    "        pass\n",
    "\n",
    "\n",
    "    \n",
    "cv.namedWindow( \"result\", cv.WINDOW_NORMAL ) # создаем главное окно\n",
    "cv.namedWindow( \"b\" ) # создаем окно настроек\n",
    "\n",
    "file_name = random_file(path_to_file_folder_fixed)\n",
    "src = cv.imread(file_name)\n",
    "src = rotate_pic(src, rotate)\n",
    "# src=cv.imdecode(np.fromfile(file_name, dtype=np.uint8), cv.IMREAD_UNCHANGED)\n",
    "cap=src\n",
    "# cap = cv.imread('6finish.jpg')\n",
    "# создаем 6 бегунков для настройки начального и конечного цвета фильтра\n",
    "cv.createTrackbar('h1', 'b', 0, 255, nothing)\n",
    "cv.createTrackbar('s1', 'b', 0, 255, nothing)\n",
    "cv.createTrackbar('v1', 'b', 0, 255, nothing)\n",
    "cv.createTrackbar('h2', 'b', 255, 255, nothing)\n",
    "cv.createTrackbar('s2', 'b', 255, 255, nothing)\n",
    "cv.createTrackbar('v2', 'b', 255, 255, nothing)\n",
    "crange = [0,0,0, 0,0,0]\n",
    "\n",
    "hsv = cv.cvtColor(src, cv.COLOR_BGR2HSV )\n",
    "\n",
    "while True:\n",
    "#     img = cv.imread('6finish.jpg')\n",
    "\n",
    "    # считываем значения бегунков\n",
    "    h1 = cv.getTrackbarPos('h1', 'b')\n",
    "    s1 = cv.getTrackbarPos('s1', 'b')\n",
    "    v1 = cv.getTrackbarPos('v1', 'b')\n",
    "    h2 = cv.getTrackbarPos('h2', 'b')\n",
    "    s2 = cv.getTrackbarPos('s2', 'b')\n",
    "    v2 = cv.getTrackbarPos('v2', 'b')\n",
    "\n",
    "\n",
    "    # формируем начальный и конечный цвет фильтра\n",
    "    h_min = np.array((h1, s1, v1), np.uint8)\n",
    "    h_max = np.array((h2, s2, v2), np.uint8)\n",
    "\n",
    "    # накладываем фильтр на кадр в модели HSV\n",
    "    thresh = cv.inRange(hsv, h_min, h_max)\n",
    "\n",
    "    cv.imshow('result', thresh) \n",
    " \n",
    "    ch = cv.waitKey(5)\n",
    "    if ch == 27:\n",
    "        break\n",
    "    if ch == 49:\n",
    "        v_min_s = cv.getTrackbarPos('v1', 'b')\n",
    "        v_max_s = cv.getTrackbarPos('v2', 'b')\n",
    "        s_min_s = cv.getTrackbarPos('s1', 'b')\n",
    "        s_max_s = cv.getTrackbarPos('s2', 'b')\n",
    "        h_max_s = cv.getTrackbarPos('h2', 'b')\n",
    "        h_min_s = cv.getTrackbarPos('h1', 'b')\n",
    "        group_param_seeds = picture_params()\n",
    "        picture_params.color(group_param_seeds,h_min_s,h_max_s,s_min_s,s_max_s,v_min_s,v_max_s)\n",
    "\n",
    "# cap.release()\n",
    "cv.destroyAllWindows()\n",
    "del src, cap, hsv, thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlb,hlt,slb,slt,vlb,vlt = group_param_leaves.return_colors()\n",
    "hrb,hrt,srb,srt,vrb,vrt = group_param_roots.return_colors()\n",
    "hsb,hst,ssb,sst,vsb,vst = group_param_seeds.return_colors()\n",
    "morph, gs,c_bottom, c_top = group_param.return_bl_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     178
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def midpoint(ptA, ptB):\n",
    "    return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n",
    "\n",
    "measure_full2 = pd.DataFrame(columns=[],index=np.arange(30))\n",
    "# ppm - pixel per metric, массив с коэфам пересчета пикселя в мм, на случай плохого поиска стикера на фото\n",
    "\n",
    "folders_list = folders_list_function(path_to_file_folder_fixed)\n",
    "# pic_num=0\n",
    "for g in folders_list:\n",
    "    path_to_file_folder = path.join(path_to_file_folder_fixed, str(g)+'/')\n",
    "    for filename_in_folder in listdir(path_to_file_folder):\n",
    "        \n",
    "        if filename_in_folder=='.ipynb_checkpoints':\n",
    "            continue\n",
    "#         pic_num +=1\n",
    "#         if pic_num>3:\n",
    "#             continue\n",
    "        ### CONTOURS ###\n",
    "\n",
    "        print('...LOOKING FOR CONTOURS...')\n",
    "\n",
    "        file_name = path.join(path_to_file_folder, filename_in_folder)\n",
    "        \n",
    "        ### Plant contour ####       \n",
    "\n",
    "        src = cv.imread(file_name)\n",
    "        src = rotate_pic(src, rotate)\n",
    "        gr = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
    "        bl=cv.GaussianBlur(src,(gs,gs),0)\n",
    "        canny = cv.Canny(bl, c_bottom, c_top)\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (morph,morph))\n",
    "        closed = cv.morphologyEx(canny, cv.MORPH_CLOSE, kernel)\n",
    "        contours0 = cv.findContours(closed.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)[0]\n",
    "        # contours0 = contours0[0] if imutils.is_cv2() else contours0[1]\n",
    "        (contours0, _) = contours.sort_contours(contours0)\n",
    "        pixelsPerMetric = None\n",
    "        quantity_of_plants = 0\n",
    "        real_conts = []\n",
    "        \n",
    "        pixelsPerMetric = find_paper(src,paper_area,paper_area_thresold, position_x_axes(src,x_pos_divider),\n",
    "                                     canny_top=c_top, canny_bottom=c_bottom,morf=morph)\n",
    "        \n",
    "        for cont in contours0:\n",
    "            if (cv.contourArea(cont)>contour_area_threshold):\n",
    "                center, radius = cv.minEnclosingCircle(cont) #recomended range of plants position is between 1/3 and 2/3\n",
    "                if ((cv.contourArea(cont) > contour_area_threshold)&\n",
    "                    (center[0] > src.shape[1]//3)&(center[0] < src.shape[1]*2//3)):\n",
    "                    real_conts.append(cont)\n",
    "#                     cv.drawContours(src,[cont],0,(255,255,5),2)\n",
    "      \n",
    "        quantity_of_plants = len(real_conts)\n",
    "        print(quantity_of_plants)\n",
    "        print(pixelsPerMetric)\n",
    "\n",
    "        ### SEEDS ###\n",
    "\n",
    "        print('...LOOKING FOR SEEDS POSITION...')\n",
    "\n",
    "        img2 = cv.imread(file_name,0)\n",
    "        img2 = rotate_pic(img2, rotate)\n",
    "        template = cv.imread(template_filename,0)\n",
    "        template = rotate_pic(template, rotate)\n",
    "    #         template = cv.cvtColor(template, cv.COLOR_BGR2GRAY)\n",
    "        w, h = template.shape[::-1]\n",
    "\n",
    "        # All the 6 methods for comparison in a list\n",
    "        # methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "        #             'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "        methods = ['cv.TM_CCOEFF_NORMED']\n",
    "        for meth in methods:\n",
    "            img = img2.copy()\n",
    "            method = eval(meth)\n",
    "            # Apply template Matching\n",
    "            res = cv.matchTemplate(img,template,method)\n",
    "            threshold = 0.55\n",
    "            loc = np.where( res > threshold)\n",
    "            x=np.array([])\n",
    "            y=np.array([])\n",
    "            for pt in zip(*loc[::-1]):\n",
    "                if (pt[0] > src.shape[1]/3)&((pt[0] < 2*src.shape[1]/3)):\n",
    "                    cv.rectangle(img, pt, (pt[0] + w, pt[1] + h), (0,0,255), 5)\n",
    "                    x=np.append(x,pt[0])\n",
    "                    y=np.append(y,pt[1])\n",
    "            slope, intercept = linear_approx(y,x)\n",
    "            p1 = [int(intercept),0]\n",
    "            p2 = [int(slope*img.shape[0]+intercept),img.shape[0]]\n",
    "            pts_leaves = np.array([[0,0],p1,p2,[0,img.shape[0]]])\n",
    "            pts_roots = np.array([[p1[0]+3*w//4,p1[1]],[p2[0]+3*w//4,p2[1]],[img.shape[1],img.shape[0]],[img.shape[1],0]])\n",
    "            plt.figure(figsize = (14,14))\n",
    "            plt.subplot(121),plt.imshow(res,cmap = 'gray')\n",
    "            plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
    "            plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "            plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
    "            plt.suptitle(meth)\n",
    "            plt.show()\n",
    "            \n",
    "        src = drop_seeds(src,hsb,hst,ssb,sst,vsb,vst)\n",
    "        src_black_seeds = src.copy()\n",
    "        src_black_seeds = cv.cvtColor(src_black_seeds, cv.COLOR_BGR2HSV)\n",
    "        ### COLOR ###\n",
    "\n",
    "        print('...MAKING COLOR...')\n",
    "\n",
    "        overlay = src.copy()\n",
    "        cv.drawContours(overlay, [pts_leaves], -1,(0,224,79), -1)\n",
    "        opacity = 0.25\n",
    "        cv.drawContours(overlay, [pts_roots], -1, (240,0,255), -5)\n",
    "        cv.addWeighted(overlay, opacity, src, 1 - opacity, 0, src)\n",
    "        bl = cv.medianBlur(src, 7)\n",
    "        bl=cv.GaussianBlur(bl,(5,   5),0)\n",
    "        img_hsv = cv.cvtColor(bl, cv.COLOR_BGR2HSV)\n",
    "        cv.imwrite('colored/{0}'.format(filename_in_folder), src)\n",
    "        print(src.shape)\n",
    "        print('mean_left_x = ', mean_left_x, 'mean_right_x  =', mean_right_x)\n",
    "\n",
    "        ## WIDTH ###\n",
    "\n",
    "        print('...WIDTH CALCULATION...')\n",
    "        measure = pd.DataFrame(columns=['roots_area_{0}'.format(file_name), 'leaves_area_{0}'.format(file_name),\n",
    "                                        'roots_length_{0}'.format(file_name), 'leaves_length_{0}'.format(file_name),\n",
    "                                        'roots_width_{0}'.format(file_name), 'leaves_width_{0}'.format(file_name),\n",
    "                                       'plant_area_{0}'.format(file_name),'seed_area_{0}'.format(file_name),\n",
    "                                       'roots_max_length_{0}'.format(file_name),'roots_max_width_{0}'.format(file_name)],\n",
    "                               index=np.arange(len(real_conts)))\n",
    "\n",
    "        \n",
    "        for i in range(quantity_of_plants):\n",
    "            is_first = True\n",
    "            is_first_r = True\n",
    "            is_first_r_max = True\n",
    "            roots = 0\n",
    "            leaves = 0\n",
    "            lamount = 0\n",
    "            ramount = 0\n",
    "            r_max_amount = 0\n",
    "            c = real_conts[i]\n",
    "            left = tuple(c[c[:, :, 0].argmin()][0])\n",
    "            right = tuple(c[c[:, :, 0].argmax()][0])\n",
    "            top = tuple(c[c[:, :, 1].argmin()][0])\n",
    "            bottom = tuple(c[c[:, :, 1].argmax()][0])\n",
    "            cv.line(img_hsv, left, right, (255, 255, 255), thickness=2)\n",
    "            step = (right[0]-mean_right_x)//3\n",
    "            if (mean_right_x-left[0])//3!=0:                \n",
    "                for y in range(left[0],mean_left_x,(mean_right_x-left[0])//3):\n",
    "                    is_first = True\n",
    "                    for x in range(top[1],bottom[1]):#иттерация по вертикали, т к img.shape => (height, width), но компонента контура (х,у)\n",
    "                        h, s, v = img_hsv[x, y]\n",
    "                        if (cv.pointPolygonTest(real_conts[i],(x,y), False)):\n",
    "                            if (v>vlb)&(h>hlb)&(h<hlt):\n",
    "                                lamount = lamount + 1*is_first\n",
    "                                is_first = False\n",
    "                                leaves += 1\n",
    "                            else:\n",
    "                                is_first = True\n",
    "                        else:\n",
    "                            is_first = True\n",
    "            else:\n",
    "                leaves_width = 0 \n",
    "\n",
    "# r_max_amaunt - счетчик для максимальной длины корня, ramount - для суммарной длины                \n",
    "                \n",
    "            if step!=0:\n",
    "                for y in range(mean_right_x, right[0],step):#идем по ввертикальным линиям   \n",
    "                    is_first_r = True\n",
    "                    is_first_r_max = True\n",
    "                    for x in range(top[1],bottom[1]):#иттерация по вертикали, т к img.shape => (height, width), но компонента контура (х,у)\n",
    "                        h, s, v = img_hsv[x, y]\n",
    "                        if (cv.pointPolygonTest(real_conts[i],(x,y), False)):# если точка внутри контура\n",
    "                            if (v>vrb)&((h>hrb)&(h<hrt)):# если эта точка = корень, а не фон \n",
    "                                ramount = ramount + 1*is_first_r#если это первое вхождение корня, то число корней+=1\n",
    "                                r_max_amount=r_max_amount+1*is_first_r_max\n",
    "                                is_first_r_max = False\n",
    "                                is_first_r = False#далее вхождение уже не первое\n",
    "                                roots += 1#число пикселей +=1\n",
    "                            else:\n",
    "                                is_first_r = True #если это не корень а фон, то вхождения нет\n",
    "                        else:\n",
    "                            is_first_r = True#если это не в контуре, то вхождения точно нет\n",
    "            if (lamount == 0.0)|(lamount == 0):\n",
    "                leaves_width = 0\n",
    "            else: \n",
    "                leaves_width = leaves/lamount\n",
    "\n",
    "            if (ramount == 0.0)|(ramount == 0)|(step == 0):\n",
    "                roots_width = 0\n",
    "                roots_max_width = 0\n",
    "            else:\n",
    "                roots_width = roots/ramount\n",
    "                roots_max_width = roots/r_max_amount\n",
    "\n",
    "            measure['roots_width_{0}'.format(file_name)].iloc[i] = roots_width\n",
    "            measure['roots_max_width_{0}'.format(file_name)].iloc[i] = roots_max_width\n",
    "            measure['leaves_width_{0}'.format(file_name)].iloc[i]= leaves_width\n",
    "\n",
    "        ### PIXEL COUNTING ###\n",
    "\n",
    "        print('...PIXEL COUNTING...')\n",
    "\n",
    "        for i in range(len(real_conts)):\n",
    "            c = real_conts[i]\n",
    "            measure.iloc[i]['plant_area_{0}'.format(file_name)] = cv.contourArea(c)\n",
    "#             measure.iloc[i]['seed_area_{0}'.format(file_name)] = seed_area\n",
    "        measure['leaves_area_{0}'.format(file_name)] =color_range_counter(src, real_conts, hlb,hlt,slb,slt,vlb,vlt)\n",
    "        measure['roots_area_{0}'.format(file_name)] =color_range_counter(src, real_conts, hrb,hrt,srb,srt,vrb,vrt)\n",
    "        measure['seed_area_{0}'.format(file_name)] =color_range_counter(src_black_seeds, real_conts, 0,1,0,1,0,1)\n",
    "        measure['plant_area_{0}'.format(file_name)] = measure['plant_area_{0}'.format(file_name)]-measure['seed_area_{0}'.format(file_name)]\n",
    "        measure['plant_area_{0}'.format(file_name)] = measure.apply(lambda x: x['plant_area_{0}'.format(file_name)]/(pixelsPerMetric*pixelsPerMetric), axis = 1 )\n",
    "        measure['roots_length_{0}'.format(file_name)] = measure['roots_area_{0}'.format(file_name)] \n",
    "        measure['leaves_length_{0}'.format(file_name)] = measure['leaves_area_{0}'.format(file_name)] \n",
    "        \n",
    "        measure['roots_length_{0}'.format(file_name)] = measure.apply(lambda x: length(x['roots_width_{0}'.format(file_name)],x['roots_area_{0}'.format(file_name)],pixelsPerMetric), axis = 1 )\n",
    "        measure['roots_max_length_{0}'.format(file_name)] = measure.apply(lambda x: length(x['roots_max_width_{0}'.format(file_name)],x['roots_area_{0}'.format(file_name)],pixelsPerMetric), axis = 1 )\n",
    "        measure['leaves_length_{0}'.format(file_name)] = measure.apply(lambda x: length(x['leaves_width_{0}'.format(file_name)],x['leaves_area_{0}'.format(file_name)],pixelsPerMetric), axis = 1 )\n",
    "        measure_full2 = measure_full2.join(measure, how = 'outer')\n",
    "\n",
    "        plt.figure(figsize = (14,14))\n",
    "        plt.imshow(src)\n",
    "        plt.show()\n",
    "print (\"{:g} s\".format(time.clock() - start_time))\n",
    "\n",
    "del res,bl,overlay, img, img2, img_hsv, gr, canny, src, closed, src_black_seeds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dicts preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = files_dicts(path_to_file_folder_fixed)\n",
    "roots_sum_dict, roots_max_dict, plant_area_dict, leaves_dict = dicts.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_germ = seed_germination(measure_full2, roots_max_dict.keys(), threshold=7, is_save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap =shapiro_test(measure_full2, dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_parameters = ['roots_sum','roots_max','plant_area','leaves']\n",
    "v= [0,0,0,0]\n",
    "p_value_dict = dict(zip(plant_parameters, v))\n",
    "for i in plant_parameters:\n",
    "    is_not_norm = any(shap[i]<0.05)\n",
    "    is_norm = not is_not_norm\n",
    "    test_type = 'test_type = '+str(is_norm*'Unpaired T-test'+is_not_norm*'Mann Whitney U-test')+'\\n' +'\\n'\n",
    "    \n",
    "    p_value_dict[i] = (p_value_function(measure_full2, dicts[i],is_norm),test_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whiskers_dict = {'roots_sum': {},\n",
    "               'roots_max': {},\n",
    "               'plant_area': {},\n",
    "               'leaves': {}}\n",
    "result_dict = {'roots_sum': '',\n",
    "               'roots_max': '',\n",
    "               'plant_area': '',\n",
    "               'leaves': '',\n",
    "              'full_file_photo_separated': measure_full2}\n",
    "\n",
    "for i in whiskers_dict.keys():\n",
    "    ylabel = 'length, mm'*(i!='plant_area')+'area, mm2'*(i=='plant_area')\n",
    "    result_dict[i], whiskers_dict[i] = bar_plot_function(i, 5, measure_full2, dicts[i], p_value_dict[i][0], ylabel=ylabel,\n",
    "                                  is_save= True, union_DF_length=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(result_dict['leaves'],result_dict['roots_max'], result_dict['roots_sum'],result_dict['plant_area'],\n",
    "     whiskers_dict,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_annotation(name, text):\n",
    "    with open(name, 'r+') as f:\n",
    "        content = f.read()\n",
    "        f.seek(0, 0)\n",
    "        f.write(text)\n",
    "        f.write(content)\n",
    "        writer = csv.writer(f)\n",
    "    \n",
    "\n",
    "report_information = ('Date and time: ' + str(datetime.datetime.now())+'\\n'+\n",
    "                      'Program settings and initial information: \\n'+ \n",
    "                      'path_to_file_folder_fixed = '+ str(path_to_file_folder_fixed)+'\\n'+\n",
    "                      'paper_area = '+str(paper_area)+'mm2; paper_area_thresold = '+str(paper_area_thresold)+'pixels \\n'+\n",
    "                      'paper threshold position = photo width/x_pos_divider = img.shape[0]/'+str(x_pos_divider)+'\\n'+\n",
    "                      'contour_area_threshold = '+str(contour_area_threshold)+' pixels \\n'+\n",
    "                      'template_filename = '+str(template_filename)+'\\n'+\n",
    "                      'leaves parameters'+ str(group_param_leaves.return_colors()) +'\\n'+\n",
    "                      'roots parameters'+str(group_param_roots.return_colors())+'\\n'+\n",
    "                      'seeds parameters'+str(group_param_seeds.return_colors())+'\\n'+\n",
    "                      'blur parameters'+str(group_param.return_bl_params())+'\\n' +'\\n' )\n",
    "\n",
    "for i in result_dict.keys():\n",
    "    report_table_filename = str(path_to_file_folder_fixed[:-1])+'_'+str(i)+'_'+str(datetime.datetime.now().date())+'.csv'\n",
    "    result_dict[i].to_csv(report_table_filename)\n",
    "\n",
    "    with open(report_table_filename, 'r+') as f:\n",
    "        content = f.read()\n",
    "        f.seek(0, 0)\n",
    "        f.write(report_information)\n",
    "        f.write(content)\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "\n",
    "shap_filename = str(path_to_file_folder_fixed[:-1])+'_shapiro_'+str(datetime.datetime.now().date())+'.csv'\n",
    "shap.to_csv(shap_filename)\n",
    "add_annotation(shap_filename, report_information)\n",
    "\n",
    "for i in whiskers_dict.keys():\n",
    "    pval_filename = str(path_to_file_folder_fixed[:-1])+'_pvalue_'+str(i)+str(datetime.datetime.now().date())+'.csv'\n",
    "    p_value_dict[i][0].to_csv(pval_filename)\n",
    "    test_type = p_value_dict[i][1]\n",
    "    add_annotation(pval_filename, report_information+test_type)\n",
    "\n",
    "seed_germ_filename = str(path_to_file_folder_fixed[:-1])+'_seed_germ_'+str(datetime.datetime.now().date())+'.csv'\n",
    "seed_germ.to_csv(seed_germ_filename)\n",
    "add_annotation(seed_germ_filename, report_information)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.263px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
